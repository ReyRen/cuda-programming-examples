### GPU架构

当启动一个内核网格时，它的线程块被分布在了可用的SM上执行。多个block可能分布在同一个SM上。

CUDA采用单指令多线程(SIMD)架构管理和执行线程。每32个线程为一组称为线程束(warp)。wrap中的所有线程同时执行相同的指令。
每个线程都有自己的指令地址计数器和寄存器状态，利用自身的数据执行当前的指令。每个SM都将分配给它的线程块分到包含32个线程
的wrap中，然后在可用的硬件资源上进行调度执行。

### SIMD vs SIMT

SIMD是单指令多数据。两者都是将相同的指令广播给多个执行单元来实现并行。

SIMD要求同一个向量中的所有元素要在一个统一的同步组中一起执行

SIMT允许属于统一wrap的多个线程独立执行，尽管一个wrap中的所有线程在相同的程序地址上同时开始执行，但是单独的线程仍有可能不同的行为。

SM和SP是物理概念，block、grid、wrap等是CUDA的软件概念。

一个block只能在一个SM上被调度。一旦block在一个SM上被调度，就会一直保存在该SM上直到执行完成。在同一时间，一个SM可以容纳多个线程块

关于wrap推荐一篇很精彩的文章[理解线程束执行的本质](https://face2ai.com/CUDA-F-3-2-%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%AC%E8%B4%A8-P1/)

SM是GPU架构的核心。寄存器和共享内存是SM中的稀缺资源。CUDA将这些资源分配到SM中的所有常驻线程里。因此，这些有限的稀缺资源限制了在SM上活跃的线程束的数量，
活跃的线程束数量对应于SM上的并行量。

### 动态并行

到目前为止，所有kernel都在host端调用，GPU的工作完全在CPU的控制下。CUDA Dynamic Parallelism允许GPU kernel在device端创建调用。Dynamic Parallelism使递归更容易实现
和理解，由于启动的配置可以由device上的thread在运行时决定，这也减少了host和device之间传递数据和执行控制。通过动态并行性，可以直到程序运行时才推迟确定在GPU上创建
有多少块和网格。
