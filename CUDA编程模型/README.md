在编程和算法设计的过程中，最关心的应是在领域曾如何解析数据和函数，以便在并行环境中能正确高效的进行。当进入编程阶段，关注点转向如何组织并发
线程。CUDA提出线程层次结构抽象的概念，允许控制线程行为。


### CUDA编程结构

**主机**： CPU及其内存(主机内存)

**设备**: GPU及其内存(设备内存)

从6.0开始，NVIDIA提出Unified Memory的编程模型，连接了主机内存和设备内存，可以用单个指针访问CPU和GPU内存，无须彼此手动拷贝。

但是目前应学会的是如何为主机和设备分配内存空间以及如何在CPU和GPU之间拷贝共享数据。这种程序员管理模式控制下的内存和数据可以优化应用
程序并实现硬件系统利用率的最大化。

**kernel**： 核函数是代码在GPU上运行。

多数情况下，主机可以独立的对设备进行操作。内核一旦被启动，管理权立刻返回给主机，释放CPU来执行设备上运行的并行代码实现的额外的任务。
CUDA编程模式是异步的，因此GPU上进行运算的同时也可以主机和设备通讯。一个典型的CUDA程序包括并行代码（GPU）互补的串行代码（CPU）。

**一个典型的cuda程序**:

1. 数据从CPU内存拷贝到GPU内存
2. 调用核函数对存储在GPU内存中的数据进行操作
3. 将数据从GPU内存传回CPU内存

如实例:

[sumArraysOnHost](https://github.com/ReyRen/cuda-programming-examples/blob/master/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/sumArraysOnHost.c)

[sumArrayOnDevice](https://github.com/ReyRen/cuda-programming-examples/blob/master/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/sumArraysOnDevice.c)

### 线程管理

由一个内核启动所产生的所有线程统称为一个网格。同一网格中的所有线程共享相同的全局内存空间。一个网格由多个线程块构成，一个线程块包含一组线程，
同一线程块内的线程协作可以通过同步、共享内存实现。不同块内的线程不能协作。

线程依靠blockIdx.xyz(线程块在线程格内的索引)和threadIx.xyz(块内的线程索引)这两个坐标变量进行区分。

通常，一个线程格会被组织成线程块的二维数组形式，一个线程块会被组织成线程的三维数组形式。

如案例[检查网络和块的索引和维度]()

**从主机端和设备端访问网络/块变量**:

区分主机端和设备端的网格和块变量的访问是很重要的。例如，声明一个主机端的块变量，按照如下定义其坐标并对其进行访问：

block.x, block.y, block.z

在设备端，已经预定义了内置块变量的大小：

blockDim.x, blockDim.y, blockDim.z

总之，在启动内核之前就定义了主机端的网格和块变量，并从主机端通过由x, y, z三个字段决定的矢量结构来访问它们。当内核启动时，可以使用内核中预初始化的内置变量。


